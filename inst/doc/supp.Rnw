%
% NOTE -- ONLY EDIT THE .Rnw FILE!!!  The .tex file is
% likely to be overwritten.
%
% \VignetteIndexEntry{Using the package ppiStats}
%\VignetteDepends{}
%\VignettePackage{ppiStats}

\documentclass[11pt]{article}    

\usepackage{color}
\definecolor{WildStrawberry}{rgb}{0.69803922,0.09411765,0.16862745}
\usepackage[%
baseurl={http://www.bioconductor.org},%
pdftitle={Supplementary Material for "Coverage and Error Models of Protein-Protein Interaction Data by Directed Graph Analysis"},%
pdfauthor={Tony Chiang},%
pdfsubject={ppiStats},%
pdfkeywords={Bioconductor},%
pagebackref,bookmarks,colorlinks,linkcolor=WildStrawberry,citecolor=WildStrawberry,%
pagecolor=WildStrawberry,raiselinks,plainpages,pdftex]{hyperref}

%----------------------------------------------------------------------
\usepackage{subfigure}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{rotating}
%% instead of \usepackage{Sweave}
\RequirePackage[T1]{fontenc}
\RequirePackage{graphicx,ae,fancyvrb}
\IfFileExists{upquote.sty}{\RequirePackage{upquote}}{}
\setkeys{Gin}{width=0.8\textwidth}
\DefineVerbatimEnvironment{Sinput}{Verbatim}{fontshape=sl}
\DefineVerbatimEnvironment{Soutput}{Verbatim}{}
\DefineVerbatimEnvironment{Scode}{Verbatim}{fontshape=sl}
\newenvironment{Schunk}{}{} 

\newcommand{\Rfunction}[1]{{\texttt{#1}}}
\newcommand{\Robject}[1]{{\texttt{#1}}}
\newcommand{\Rpackage}[1]{{\textit{#1}}}
\newcommand{\Rclass}[1]{{\textit{#1}}}
\newcommand{\mbs}[1]{{\mbox{\scriptsize #1}}}
\newcommand{\pfp}{p_{\mbox{\scriptsize fp}}}
\newcommand{\pfn}{p_{\mbox{\scriptsize fn}}}
\newcommand{\ptp}{p_{\mbox{\scriptsize tp}}}
\newcommand{\ptn}{p_{\mbox{\scriptsize tn}}}
\newcommand{\ntot}{n_{\mbox{\scriptsize tot}}}

\newcommand{\myincfig}[3]{%
 \begin{figure}[tp] \begin{center}
    \includegraphics[width=#2]{#1}
    \caption{\label{#1}#3}
 \end{center} \end{figure}
}

\SweaveOpts{prefix.string=fig}
%----------------------------------------------------------------------

\setkeys{Gin}{width=0.9\textwidth}
<<loadlibs,echo=FALSE, results = hide>>=
library("ppiStats")

library("yeastExpData")
library("lattice")
library("grid")
library("Biobase")
library("xtable")
library("RColorBrewer")
data("proteinProperties")
library("Matrix")
options(warn=0, error=recover, width=63)
@ 

<<ppiData, echo=FALSE, results=hide>>=
library("ppiData")
get(bpExperimentNames[8])
bpGraphs = new.env(parent=globalenv(), hash=FALSE)
data(list=bpExperimentNames, envir=bpGraphs)
for(j in ls(bpGraphs))
  assign(j, eval(get(j, env=bpGraphs)), env=bpGraphs)
@ 

<<createEDATable, echo=FALSE, results=hide>>=
## remove the "BPGraph", but keep a "-" if it is followed by a number
dNames <- sub("-$", "", sub("BPGraph", "-", bpExperimentNames))
numVB <- listLen(viableBaits)
numVP <- listLen(viablePrey)
numVBP <- mapply(function(x,y) {length(intersect(x,y))}, viableBaits, viablePrey)
nI  <- unlist(eapply(bpGraphs, function(x) {sum(sapply(x@edgeL, function(y) {length(y[[1]])}))}))[bpExperimentNames]
nI2 <- unlist(eapply(bpGraphs, function(g) {d=degree(g); s=sum(d$inDegree); stopifnot(s==sum(d$outDegree)); return(s)}))
numInteractions <- unlist(eapply(bpGraphs, function(g) sum(degree(g)$inDegree)))

## eventually, nI and nI2 can be dropped:
stopifnot(identical(sort(as.integer(nI)), sort(as.integer(nI2))), 
          identical(sort(as.integer(nI)), sort(as.integer(numInteractions))))
rm(list=c("nI", "nI2"))
 
## need to find homodimers

numCB <- c(NA,NA,NA,NA,NA,NA,NA,600,589,165,1993,2357)
numTB <- c(6604,31,22,100,1,6604,192,725,1739,165,6466,4562)

EDA <- data.frame(
 "Ref."=I(paste("\\cite{", dNames, "}", sep="")),
 VB=numVB,
 CB=numCB,
 TB=numTB,
 "VB/TB"=round(numVB/numTB, digit=2),
 VP=numVP,
 VBP=numVBP,
 "VBP/BP"=round(numVBP/numVB, digit=2),
 "VP/VB"=round(numVP/numVB,digit=2),
 "TI"=numInteractions,
"TI/VB"=round(numInteractions/numVB,digit=2), 
check.names=FALSE,  row.names=dNames)

@

\begin{document}

%----------------------------------------------------------------------
\title{Supplementary Material for "Coverage and Error Models of 
  Protein-Protein Interaction Data by Directed Graph Analysis"}
% ---------------------------------------------------------------------

\author{Tony Chiang 
% \correspondingauthor$^{1,2}$%
%  \email{Tony Chiang - tchiang@ebi.ac.uk}
\and Denise Scholtens %$^3$%
%       \email{Denise Scholtens - dscholtens@northwestern.edu}\
\and Deepayan Sarkar% $^2$%
%      \email{Deepayan Sarkar - dsarkar@fhcrc.org}\and
\and Robert Gentleman%$^2$%
%       \email{Robert Gentleman - rgentlem@fhcrc.org}\and
\and Wolfgang Huber%$^1$%
%       \email{Wolfgang Huber - huber@ebi.ac.uk}
}

\date{\today}
\maketitle
\tableofcontents

\begin{abstract}
This compendium serves as a supplementary source of materials for the
analysis presented in \emph{Coverage and Error Models of Protein-Protein
Interaction Data by Directed Graph Analysis}.
We provide all necessary materials, methods, and code to reproduce
the analysis, and present additional results.
\end{abstract}

\section{Introduction}
This technical report accompanies the paper \emph{Coverage and Error
Models of Protein-Protein Interaction Data by Directed Graph Analysis}
by Chiang et al.  It explains all the steps taken to perform the
analysis of protein interaction data described in that paper.  This
report has been produced as a \emph{reproducible document}: it
contains all the computer instructions to reproduce the analysis and
to create the figures, tables and numeric results of the paper.  In
addition, further analyses are produced that extend and support the
main results described in the paper.

The production of the reproducible document employs the computational
system and language R and the add-on packages \Rpackage{ppiStats},
\Rpackage{ppiData}, and \Rpackage{yeastExpData}.  You will need R
version 2.4.1 or greater together with recent versions of the three
packages and some other add-on packages that they depend
upon and which can be obtain from CRAN or Bioconductor.  To reproduce
the computations shown here, you do not need to type them or
copy-paste them from the PDF file; rather, you can take the file
supp.Rnw in the doc directory of the \Rpackage{ppiStats} package, open
it in a text editor, run it using the R command Sweave; and if you
wish, modify the program it to your needs. Alternatively, if you would
simply like the code without the surrounding text, you can call
Rtangle on the supp.Rnw file to generate a script file called supp.R.

\section{Obtaining the PPI Data}
We begin by detailing the methods by which we obtained the 12 protein 
interaction datasets. We wanted data that had two properties: 1. 
information on the bait/prey data is preserved and 2. the prey population 
is documented as genome-wide. We downloaded the protein 
interaction data of \cite{Ito2001, Uetz2000, Zhao2005, Cagney2001, 
Tong2002, Hazbun2003, Gavin2006} from the \emph{IntAct} repository. 
We obtained \cite{Gavin2002, Ho2002, Krogan2004, Krogan2006} from their 
primary sources. Having obtained the bait/prey protein interaction
data, we created an R data-package \Rpackage{ppiData} where we stored this 
data. Each dataset is stored in \Rpackage{ppiData} as a directed 
graph object. As an example, we have selected 4 proteins from the 
\cite{Krogan2006} dataset and rendered the vertex induced subgraph in
Figure~\ref{fig:egKrogan06}.

<<egKrogan06, fig=TRUE, width=3, height=3.5, prefix=FALSE, include=FALSE, echo=FALSE, results=hide>>=
if(!exists("egKrogan06"))
  load("egKrogan06.rda")

par(mai=rep(0,4), lwd=2)
stopifnot(identical(nodes(egKrogan06), c("YAL005C", "YBR092C", "YBR118W", "YPR190C")))
trivialnames = c("SSA1", "PHO3", "TEF2", "RPC82C")
plot(egKrogan06, "dot", nodeAttrs=makeNodeAttrs(egKrogan06, 
  fillcolor=brewer.pal(9, "Pastel1")[c(2, 9, 2, 2)],
  label=trivialnames, width="3", height="1.2",
  shape="ellipse"))
@ 

%
\begin{figure}
\centering
\includegraphics[width=45mm]{egKrogan06}
\caption{\label{fig:egKrogan06}% 
  The graph shows the interaction data between four selected proteins from 
  Krogan et al.'s experiment~\cite{Krogan2006}. The bi-directional edge 
  between the ATPase \textit{SSA1} and the translational elongation factor 
  \textit{TEF2} indicates that either one as a bait pulled down the 
  other one as a prey. The directed edge from \textit{RPC82}, a subunit 
  of RNA polymerase III, to \textit{SSA1} indicates that \textit{RPC82} 
  as a bait pulled down \textit{SSA1}, but not vice versa. Another 
  unreciprocated edge goes from the phosphatase \textit{PHO3} to
  \textit{TEF2}.  An investigation of the dataset shows that \textit{PHO3}, 
  which localizes in the periplasmatic space, was not reported in any 
  interaction as a prey, while \textit{RPC82C} was. In the interpretation 
  of the data, we would have most confidence that there is a real 
  interaction between \textit{SSA1} and \textit{TEF2}. We can differentiate 
  between the two unreciprocated interactions: the one between \textit{RPC82C} 
  and \textit{SSA1} has been bi-directionally tested, but only found once, 
  while the other one has only been uni-directionally tested and found.
}
\end{figure}

To make the dialogue clear, we first define some terms that will be 
used throughout this document:

\begin{itemize}

\item[] \textbf{Bait:} 
  A protein sampled for the purposes of ascertaining the 
  proteins with which it interacts. 
  The set of baits used in an experiment is the bait population. 
\item[] \textbf{Cloned Bait:} 
  A bait that was successfully cloned in a yeast cell with either
  a binding domain (Y2H) or a specified tag (AP-MS). 
\item[] \textbf{Viable Bait:} 
  A cloned bait that was observed to detect one or more proteins (prey). 
\item[] \textbf{Prey:} 
  A protein that is tested against the bait proteins. The set of prey used 
  in an experiment is the prey population. 
\item[] \textbf{Cloned Prey:} 
  For Y2H, any prey that was successfully cloned
  in a yeast cell with an activation domain. 
\item[] \textbf{Viable Prey:} 
  A prey that was found to interact with a viable bait. 
  Sometimes referred to as a \textit{hit}.
\item[] \textbf{Viable bait-prey:} 
  A protein that is both a viable bait and a 
  viable prey.
\end{itemize}


%% FIXME: please use \Robject, \Rfunction etc. instead of \emph
The vector \Robject{bpExperimentNames} contains the names to each 
of the digraph objects. In addition, two list objects (called
\emph{viableBaits} and \emph{viablePrey}) contain the viable
baits and viable prey for each experimental dataset respectively.
To represent all the data uniformly, the identifier for 
each protein is given by its corresponding Open Reading Frame
(ORF). If the ORF is unavailable, either the protein common name 
or another identifier (IntAct accension code, SwissProt ID, etc) 
is used. 

<<ppiData, echo=TRUE>>=
data("bpExperimentNames")
bpExperimentNames
get(bpExperimentNames[8])
@ 

In addition to \Rpackage{ppiData}, another R-data package, 
\Rpackage{yeastExpData}, and the R package \Rpackage{ppiStats}
were generated. \Rpackage{yeastExpData} contains R objects that
describe yeast protein abundance, 
% FIXME this is somewhat imprecise. Should say that this R object
% contains a published dataset on protein abundance, and cite the reference.
yeast GFP fusion data, and 
a R dataframe consisting of 33 other yeast protein properties
obtained from SGD (the dataframe is called \Robject{proteinProperties}). 
The \Rpackage{ppiStats} package contains all the statistical methods 
we have developed for the analysis of the directed protein interaction 
data.

<<ppiData, echo=FALSE, results=hide>>=
library("yeastExpData")
data(proteinProperties)
@ 

\section{Sampling}
\subsection{Analysis on the Bait/Prey Interactions}
We addressed the issue of sampling initially by the viable bait 
and viable prey population observed in the experimental datasets.
From the directed graphs, we created the two lists 
\Robject{viableBaits} and \Robject{viablePrey} by asking if
each protein as a vertex had non-zero out- and in-degree 
respectively modulo self-loops (i.e homomers). From these
two lists, we were able to find the set theoretic intersections
of the viable baits (VB) and viable prey (VP) per experiment to 
ascertain the viable bait/prey (VBP) populations. 

<<vbp>>=
vbp <- mapply(intersect, viableBaits, viablePrey)
@  

From SGD, we used 6466 as the number of known and characterized 
yeast ORFs. This allowed us to build bar charts (cf Figure~\ref{fig:barcharts})
to gauge the proportion of the yeast interactome tested by each 
experimental dataset. 

     \begin{figure}
       \centering
       \subfigure{\includegraphics[width=10cm]{fig1.pdf}}
       \caption{
         \label{fig:barcharts}{
           This bar chart shows the proportion of proteins sampled either as a 
           viable bait (VB), a viable prey (VP), or as both (VBP). With the 
           exception of the Krogan et al.~\cite{Krogan2006}'s data, the other
           eleven show large portions of the yeast genome which did not 
           participate in any positive interactions. Without additional 
           information, there is little we can do to elucidate whether these
           proteins were tested but inactive for all tests, or whether these 
           proteins were not tested.            
         }
       }
     \end{figure}

In addition to the bar chart, we were able to generate a number of 
sampling statistics that are otherwise undocumentd on a per experiment
% FIXME not clear what ``otherwise undocumentd on a per experiment
% setting'' means, can you precisify (or remove)?
setting (cf Table~\ref{table:perexpt}), as well as between experiments
of the same type, i.e. those which used the same system to test
interactions (cf Table~\ref{table:betweenexpt}). 

<<fig1, fig=TRUE, width=6, height=4, prefix=FALSE, include=FALSE, echo=FALSE, results=hide>>=

wh <- c(6, 7, 8, 11, 10, 12)
tot <- 6466

EDAsub <- 
    with(EDA, 
         data.frame(Expt = rownames(EDA),
                    VB   = VB - VBP,
                    VBP  = VBP,
                    VP   = VP - VBP,
                    unt  = tot - (VB + VP - VBP)))

bcol <- c(brewer.pal(9, "Pastel1")[9], brewer.pal(12, "Paired")[1:3])[c(2, 3, 4, 1)]

bc <- barchart(reorder(Expt, -unt) ~ VB + VBP + VP + unt, 
             data = EDAsub, stack = TRUE,
             auto.key = 
             list(text = c("Viable Bait only", "Both Viable Prey and Bait", "Viable Prey only", "Absent"),
                  columns = 1, adj = 1), 
             xlab = "Number of proteins",
             par.settings = list(superpose.polygon = list(border = "transparent", col = bcol )))

plot(bc)
@ 

Before we conduct any other statistical tests on the protein interaction data,
we list the definitions of some standard statistical terms in 
Table~\ref{tab:errorterms}. Any of these terms used throughout this document 
(as well as the article \emph{Coverage and Error Models in Protein Interaction
Data by Directed Graph Analysis}) corresponds to the given definitions.

\begin{table}
\begin{tabular}{p{0.30\textwidth}p{0.05\textwidth}p{0.55\textwidth}}
\hline
\multicolumn{3}{c}{\textbf{Error Statistics}} \\\hline\hline
True Positives& TP & Number of cases in which a true interaction is 
experimentally observed.\\
True Negatives& TN & Number of cases in which two proteins do not
interact, their interaction is tested, but not observed.\\
False Positives& FP & Number of cases in which two proteins do not 
interact, but an interaction is reported by the experiment.\\
False Negatives& FN & Number of cases in which a true interaction is
experimentally tested and not found.\\
\raggedright{True Tested Interactions}& P & TP+FN\\
\raggedright{True Tested Non-interactions} & N & TN+FP\\
\raggedright{False Positive Rate}&$p_{\mbs{FP}}$& Probability 
that a truely absent interaction is detected. It can be 
estimated by FP / N.\\
\raggedright{False Negative Rate}&$p_{\mbs{FN}}$& Probability 
that a true interaction is not detected. It can be estimated  by
FN / P.\\
Sensitivity&& Probability that a true interaction is detected. 
It can be estimated by TP / P.\\
Specificity&& Probability that a truely absent interaction is not 
detected, estimated by TN / N.\\
\raggedright{False Discovery Rate}&FDR&Informally, the expectated value
of FP/(TP+FP)~\cite{Storey2002}.\\
\raggedright{Positive Predictive Value}&PPV& Probability that 
an observed interaction is indeed true. It can be estimated 
by TP / (TP+FP).\\
\raggedright{Negative Predictive Value}&NPV& Probability that 
an observed non-interaction is truely absent. It can be estimated 
by TN / (TN+FN).\\ \hline\\[-2mm]
\end{tabular}
\caption{\label{tab:errorterms}% 
Standard definitions of various error
terms \cite{MethodsObsEpi}. The probabilities are conditional on that 
the interaction is tested.}.
\end{table}


\subsection{Hypergeometric Testing}
We wanted to ascertain if the viably tested proteins showed
signs of being affected by a selection bias in the experimental assay. 
To investigate, we used the conditional hypergeometric tests
described by \cite{Falcon2006} to test for over/under 
representation in GO categories. Using the R software packages
\Rpackage{Category} and \Rpackage{GOstats}, we were able
to asses these questions. For our purposes, we used a p-value 
cutoff at the $10^{-2}$ threshold. We were only interested in 
GO categories which contained at least 50 unique annotations 
as well. Both these parameters can be set by the user, and 
those familiar with the R programming language are free
to manipulate these parameters within the R scripts.

The code written to conduct these hypergeometric tests has been 
supplied with the main article as an additional file. It can 
also be found in the Script directory of the 
\Rpackage{ppiStats} package.
% FIXME: this is confusing - why isn't the code part of this script?
% and if it is not, please give the exact name and location of the script
% There is no Script directory in the ppiStats package.
%
% I don't like to idea of supplying lots of little scattered files to GB 
%  - just give them the ppiStats_x.y.z.tar.gz file with everything in it 
% at the proper place!



\section{Systematic Bias}
%--------------------------------------------------
\subsection{Probability model}
%--------------------------------------------------
For a protein $\rho$ from VBP, we want to construct a 
probability model for the joint distribution of  
$N_{R}$, the number of reciprocated edges,
$N_{I}$, the number of unreciprocated in-edges, and
$N_{O}$, the number of unreciprocated out-edges,
given the true degree $\delta^*$ and the 
parameters $\pfp$, $\pfn$ and $N \equiv |VBP|$.

We will use the shortcut
$N_{U} = N_{I} + N_{O}$ for
the total number of unreciprocated edges, and
$\Theta=\left(\delta^*, \pfp, \pfn, N \right)$ 
for the parameters.

We consider
\begin{eqnarray}
\lefteqn{P\left(
  N_{R} = n_r,
  N_{I}  = n_i,
  N_{O} = n_o \,;\,  \Theta\right) } \nonumber\\
& = &
  P(N_{I}=n_i, N_{O}=n_u-n_i \,|\,
    N_{U} = n_u, N_{R} = n_r \,;\Theta ) \nonumber\\
&&\times  P(N_{U} = n_u, N_{R} = n_r\,;\, \Theta) \label{eq:prob}
\end{eqnarray}
The decomposition of $P$ in the right hand side will be useful.

For convenience, we suppress the index $\rho$ in our notation, but please
keep in mind that the parameter $\delta^*\equiv \delta_{\rho}^*$ depends on
$\rho$, and that $N_{R}$, $N_{I}$, $N_{O}$
and $N_{U}$ are random variables that depend on $\rho$.
$N$ is an experiment-wide parameter, and we also consider 
$\pfp$ and $\pfn$ to be experiment-wide; although some
of what follows might also apply to a model where $\pfp$ and
$\pfn$ depend on $\rho$, if there were data to estimate them.

We will now make some modeling assumptions.  If we find that
the data for a particular protein does not concur well with these
assumptions, we will consider it subject to systematic error.

%--------------------------------------------------
\subsubsection{Symmetry}
%--------------------------------------------------
The first assumption is that of symmetry, that is, equality of
the distributions of $N_{I}$ and $N_{O}$.
\begin{equation}
     N_{I} =_d N_{O}
\end{equation}
and in particular
\begin{equation}\label{eq:symm}
     \left(N_{I}  | N_{U}=n_u\right) 
\sim \mbox{B}(n_u, \frac{1}{2}).
\end{equation}
This gives us the first term on the RHS of~\eqref{eq:prob}. 
The remarkable thing is that it depends on $n_u$, but not on any of
the parameters! Now for the second term:

%--------------------------------------------------
\subsubsection{Decomposition}
%--------------------------------------------------
We can decompose $N_{R}$ and
$N_{U}$ into those counts that originate from
real interactions (i.\,e.\ that are true) and those that originate
from false positive measurements.
\begin{eqnarray}
N_{R}   &=& N_{R}^v    + N_{R}^f \\
N_{U} &=& N_{U}^v  + N_{U}^f
\end{eqnarray}

The false positives are easy:
\begin{eqnarray}
N_{R}^f   &\sim& \mbox{B}(N-\delta^*-1, \, \pfp^2) \nonumber\\
N_{U}^f &\sim& \mbox{B}(N-\delta^*-1, \, 2\pfp(1-\pfp)) 
\label{eq:fps}
\end{eqnarray}

The ones that originate from a real interaction follow a multinomial
distribution
\begin{eqnarray}
\lefteqn{P(N_{R}^v   = n_{r}^v, \,
           N_{U}^v = n_{u}^v \, | \, \Theta)} \nonumber\\ 
&=&    (1-p)^{2n_{r}^v} \cdot 
\left(2p(1-p)\right)^{n_{u}^v} \cdot 
           p^{2n_{\mbs{none}}^v} \cdot 
  \frac{\delta^*!}{n_{r}^v! n_{u}^v! n_{\mbs{none}}^v!} \label{eq:multinomial}
\end{eqnarray}
where for notational convenience I used the abbreviations
$n_{\mbs{none}}^v=\delta^* - n_{r}^v - n_{u}^v$ 
and $p\equiv \pfn$.

The density function of the second term on the RHS of~\eqref{eq:prob}
can then be obtained by convolution of \eqref{eq:fps} and
\eqref{eq:multinomial}. For each value of the parameters
$\Theta\equiv(N, \delta^*, \pfp, \pfn)$, this is a 2D
matrix with infinite numbers of rows and columns, corresponding to
$n_{r}$ and $n_{u}$. Most of the probability mass, however, is 
concentrated within a bounded range.  Furthermore,
we will restrict our attention to values of $\delta^*$ between 0 and
$\delta^*_{\mbs{max}}$, depending on the data set.  This is
implemented in the function \Rfunction{nullDistDoublyTestedEdges} in
the package \Rpackage{ppiStats}.



<<bpMat, echo=FALSE, results=hide, cache=TRUE>>=



makeBPMat <- function(){
  bpMat = new.env(parent=globalenv(), hash=FALSE)
  for(g in bpExperimentNames) {
    m = as(get(g), "matrix")
    ## delete self-edges
    diag(m) = 0  

    stopifnot(identical(rownames(m), colnames(m)))
    vbp = rownames(m)[ (rowSums(m)>0) & (colSums(m)>0) ]

    m = m[vbp, vbp]

    if(nrow(m)>1) {
      assign(g, m, envir=bpMat)
    } else {
      cat(sprintf("Omitting %s, there is nothing much to do.\n", g))
    }
  }
  return(bpMat)
}

cache(bpMat <- makeBPMat())

@

%----------------------------------------
%\subsubsection*{Calculating degrees}
%----------------------------------------
%The following function is useful for the 
%subsequent calculations. Given a matrix from \Robject{bpMat},
%it calculates
%\begin{description}
%\item[\Robject{nr}] the number of reciprocated edges,
%\item[\Robject{no}] the number of unreciprocated out-edges, 
%\item[\Robject{ni}] the number of unreciprocated in-edges.
%\end{description}
%
<<calcDegrees, echo=FALSE, results=hide>>= 

## testCase <- rbind(c(0,0,0,0), c(1,0,1,1), c(0,1,0,1), c(0,0,1,0))
## dimnames(testCase) <- list(letters[1:4],letters[1:4])

getDegrees = function(m) { 
  stopifnot(all(m %in% 0:1))
  m = m>0
  cbind(nr=rowSums(m&t(m)), no=rowSums(m&(!t(m))), ni=rowSums((!m)&t(m)))
}
@ 

%----------------------------------------
\subsubsection{Using in/out asymmetry to identify baits that are likely
  to be subject to systematic errors}\label{sec:inout}
%----------------------------------------
We now use Equation~\eqref{eq:symm} to assign a $p$-value
to each protein. For a protein with unreciprocated degrees 
$(n_{i}, n_{o})$, the $p$-value is
%
\begin{eqnarray}
p(n_{i}, n_{o}) &=& 
P(\mbox{min}\{ N_{I}, N_{O} \} \le  \mbox{min}\{ n_{i}, n_{o} \} ) \nonumber\\
&=& \max 
\{ 2P(N_{I} \le  \mbox{min}\{n_{i}, n_{o}\}), \, 1 \}
\label{symmpvalue}
\end{eqnarray}
%

This is computed by the following function \Rfunction{assessSymmetry} which
is also contained in the R package \Rpackage{ppiStats}. In addition,
the function also calculates the contours of the function 
$p$ in the $(n_{i}, n_{o})$-plane. These will be used in the plots.





<<scpFun, echo=FALSE, results=hide>>=
pLevels = 1e-4
stopifnot(length(pLevels)==1)## this particular pvalColor function assumes that
pvalColors = function(x) brewer.pal(3, "Paired")[1+(x<pLevels)]
  
##  pvalColors = colorRampPalette(c("orange", "darkblue"))(length(pLevels)+2)[cut(x, c(0, pLevels, 1), include.lowest=TRUE)]

scpFun = function(f, what) {
  switch(what,
         identity = {
           trsf = function(x) x
           xlab = expression(n['out'])
           ylab = expression(n['in'])
         },
         sqrt = {
           trsf = function(x) sign(x)*sqrt(abs(x))
           xlab = expression(sqrt(n['out']))
           ylab = expression(sqrt(n['in']))
         })

  plx   = trsf(jitter(f$deg[, c('no', 'ni')]))
  axlim = c(0, max(plx))
  par(mai=c(0.9, 0.95, 0.01, 0.005), cex.lab = 2.5)
  plot(plx, xlim=axlim, ylim=axlim,
       xlab=xlab, ylab=ylab, pch=20, main="",
       col=pvalColors(f$p))

  for(k in 1:ncol(f$contours)) {
    px = f$contours[,k]
    py = (0:(length(px)-1)) - px
    lines(trsf(px), trsf(py), col="#808080")
    lines(trsf(py), trsf(px), col="#808080")
  }
}
@ 

%
Now we are ready to apply the symmetry $p$-values, and we will create
an environment, \Robject{bpRed} containing the reduced set of data 
with only proteins with $p$-values larger than or equal to p-value 
threshold of $10^{-2}$.
%

<<pThresh, echo=FALSE, results=hide>>=
pThresh = 0.01
bpRed = new.env(parent=globalenv(), hash=FALSE)

out = file("unrecipInOutDistribIncludes.tex", open="wt")

for(name in ls(bpMat)) {
  f = assessSymmetry(bpMat[[name]])
  sel = (f$p>=pThresh)
  assign(name, bpMat[[name]][sel, sel], envir=bpRed)

  myPDF = function(x, ch, ...) {
    fn = sprintf("scp-%s-%s.pdf", name, ch)
    pdf(file=fn, ...)
    x
    dev.off()
    return(fn)
  }
  myEPS = function(x, ch, ...) {
    fn = sprintf("scp-%s-%s.eps", name, ch)
    postscript(file=fn, horizontal = FALSE, onefile = FALSE, paper = "special", ...)
    x
    dev.off()
    return(fn)
  }

  f1=myPDF(scpFun(f, "identity"), ch="ident", width=4, height=4)
  f2=myPDF(scpFun(f, "sqrt"), ch="sqrt", width=4, height=4)
  f2e=myEPS(scpFun(f, "sqrt"), ch="sqrt", width=4, height=4)
  f3=myPDF(hist(f$p, main=name, xlab='p', col="#e6f598", breaks=seq(0, 1, by=0.01)), 
    ch="hist", width=6, height=2.1)

  cat("\\begin{figure}[tp]\\begin{center}\n", file=out)
  cat(sprintf("\\includegraphics[width=0.5\\textwidth]{%s}\n", f1), file=out)
  cat(sprintf("\\includegraphics[width=0.5\\textwidth]{%s}\\\n", f2), file=out)
  cat(sprintf("\\includegraphics[width=0.8\\textwidth]{%s}\n", f3), file=out)
  cat(sprintf("\\caption{Scatterplots of in- and out-degree and symmetry $p$-values for %s}\n", name), file=out)
  cat("\\end{center}\\end{figure}\n", file=out)
}

close(out)
@ 

For a more illuminating visual effect, we have perturbed the data on each
point of the figures. This perturbation shows the relative concentration 
of data for each point in each of the figures. 


\include{unrecipInOutDistribIncludes}

\subsection{Logistic Regressions}

For a protein with $n_{i}$ unreciprocated in-edges and $n_{o}$
unreciprocated out-edges, we expect
\[
n_{i} ~|~ n_{u} ~~~ \sim \mathcal{B}\left( n_{u}, 
  \frac{1}{2} \right)
\]
if false positive and false negative errors are independent of a
protein's properties.  Let $p$ be the true probability ($H_0: p =
\frac{1}{2}$) for any particular protein.  We will
\begin{itemize}
\item Perform binomial tests for $H_1: p < \frac{1}{2}$ and $H_1: p > 
  \frac{1}{2}$ for
  each protein (in each experiment)
\item Use test outcomes as responses to fit logistic regressions with
  abundance and CAI as predictor \footnote{We actually use logarithm (base 2)
    of abundance and CAI as predictor since that has a much more symmetric
    distribution.}.
\end{itemize}
Regression is restricted to the subgraph of proteins that are VBP.

<<setupLogReg,results=hide,echo=FALSE,results=hide>>=
data(gfp)
data(proteinProperties)
data(fcabundance)
@ 

<<init,results=hide,echo=FALSE,cache=TRUE>>=

## The ultimate goal here is to do enough to see if unrecipInDegree is
## significantly larger (smaller) than unrecipOutDegree for each
## protein, and see if that dependence is related to abundance.  As the
## first step, we'll just create a data frame with enough information
## to proceed.



### some EDA (may need extra code)

## fm <- 
##     glm(resp ~ abundance, 
##         allExptInfo$Krogan2006BPGraph, 
##         family = binomial())

## summary(fm)$coef
## summary(update(fm, subset = (abundance > 7)))$coef
## summary(update(fm, subset = (abundance > 9)))$coef
## summary(update(fm, subset = (abundance > 11)))$coef
## summary(update(fm, subset = (abundance > 13)))$coef


## xyplot(as.numeric(in.large.pval < 0.05) ~ logCAI + abundance, 
##        allExptInfo$Krogan2006BPGraph, 
##        outer = TRUE, 
##        scales = list(x = "free"), 
##        type = c("p", "smooth"), 
##        col.line = "red", 
##        ## subset = unrecipInDegree > 0 & unrecipOutDegree > 0, 
##        span = 0.3, family = "gaussian")




degInfo <-
    function(gname, justViable = TRUE)
{
    message("processing ", gname)
    gobj <- get(gname)
    if (justViable)
        gobj <- 
            subGraph(snodes = intersect(viableBaits[[gname]], viablePrey[[gname]]),
                     graph = gobj)
    degStat <- calcInOutDegStats(gobj)
    ans <- ## would prefer better rownames designation
        with(degStat,
             data.frame(inDegree = inDegree,
                        outDegree = outDegree,
                        unrecipInDegree = unrecipInDegree,
                        unrecipOutDegree = unrecipOutDegree))
    ans$log.abundance <- log2(gfp[rownames(ans), "abundance"])
    ans$log.cai <- log2(proteinProperties[rownames(ans), "cai"])
    ans$log.yepd <- log2(fcabundance[rownames(ans), "YEPD.mean"])
    ans$log.sd <- log2(fcabundance[rownames(ans), "SD.mean"])
    ans
}


## the second step is to perform the binomial tests

binomTests <-
    function(ginfo)
{
    ginfo$size <- with(ginfo, unrecipInDegree + unrecipOutDegree)
    ## test if unrecipOutDegree is unusually small (i.e. indegree large)
    ginfo$in.large.pval <- 
        with(ginfo,
             pbinom(unrecipOutDegree, size, 0.5, lower = TRUE))
    ## test if unrecipInDegree is unusually small (i.e. outdegree large)
    ginfo$out.large.pval <- 
        with(ginfo,
             pbinom(unrecipInDegree, size, 0.5, lower = TRUE))
    ginfo
}



logisticTests <- 
    function(ginfo, pval.cutoff = 0.05, 
             which.test = c("large.indegree", "small.indegree"), 
             family = binomial(), 
             formula = resp ~ abundance, 
             ...)
{ 
    which.test <- match.arg(which.test) 
    ginfo$resp <- 
        as.numeric(switch(which.test,
                          large.indegree = ginfo$in.large.pval, 
                          small.indegree = ginfo$out.large.pval) < pval.cutoff)
    glm(formula, ginfo, family = family, ...)  
}



##
@ 


\newpage

\subsection{Results: log(abundance) as predictor}

<<calc,echo=FALSE,results=hide,cache=TRUE>>=

exptsToTry <- bpExperimentNames[bpExperimentNames != "Zhao2005BPGraph"]

allExptInfo <- lapply(exptsToTry, degInfo)
names(allExptInfo) <- exptsToTry

allExptInfo <- lapply(allExptInfo, binomTests)


##
@ 


<<showAbundance,cache=FALSE,echo=FALSE>>=

logistic.inlarge <-
    lapply(allExptInfo, logisticTests,
           pval.cutoff = 0.05,
           formula = resp ~ log.abundance,
           which.test = "large")

logistic.outlarge <-
    lapply(allExptInfo, logisticTests,
           pval.cutoff = 0.05,
           formula = resp ~ log.abundance,
           which.test = "small")

cat("Systematic := unusually large in-degree", fill = TRUE)
do.call(rbind, 
        lapply(logistic.inlarge,
               function(x) round(summary(x)$coef[2, c(1, 2, 4), drop = TRUE], 7)))

cat("Systematic := unusually large out-degree", fill = TRUE)
do.call(rbind, 
        lapply(logistic.outlarge,
               function(x) round(summary(x)$coef[2, c(1, 2, 4), drop = TRUE], 7)))

##
@ 



\newpage

\subsection{Results: log(CAI) as predictor}



<<showLogCAI,cache=FALSE,echo=FALSE>>=

logistic.inlarge <-
    lapply(allExptInfo, logisticTests,
           pval.cutoff = 0.05,
           formula = resp ~ log.cai,
           which.test = "large")

logistic.outlarge <-
    lapply(allExptInfo, logisticTests,
           pval.cutoff = 0.05,
           formula = resp ~ log.cai,
           which.test = "small")

cat("Systematic := unusually large in-degree", fill = TRUE)
do.call(rbind, 
        lapply(logistic.inlarge,
               function(x) try(round(summary(x)$coef[2, c(1, 2, 4), drop = TRUE], 7))))

cat("Systematic := unusually large out-degree", fill = TRUE)
do.call(rbind, 
        lapply(logistic.outlarge,
               function(x) try(round(summary(x)$coef[2, c(1, 2, 4), drop = TRUE], 7))))

##
@ 

In addition to the Logistic Regressions, we plotted the adjacency matrix 
diagram of the bait/prey interactions in two different ways: 1. the rows 
and columns randomly ordered and 2. the rows and columns ordered by ascending 
CAI (cf Figure~\ref{fig:caiplots}). This readily gives a visual method of 
identifying the association between CAI and proteins rejecting the 2-sided 
Binomial test.

<<GavinMat, include=FALSE, echo=FALSE, results=hide>>=

experiment <- "Gavin2006BPGraph"
## experiment <- "Krogan2006BPGraph"

keep <- vbp[[experiment]] ## VBP only

### The following is interesting, in the sense that it gives 
### different-looking things in Krogan2006 and Gavin2006 

## keep <- viablePrey[[experiment]] 

smat <- as(get(experiment), "sparseMatrix")[keep, keep]
ord.CAI <- order(proteinProperties[rownames(smat), "cai"])
ord.random <- sample(seq_len(nrow(smat)))


mat.random <- 

    image((smat - smat * t(smat))[ord.random, ord.random],
          aspect = "iso",
          xlab = "Prey",
          ylab = "Bait",
          main = "Random Order", 
          colorkey = FALSE, sub = "")
          
mat.CAI <- 

    image((smat - smat * t(smat))[ord.CAI, ord.CAI],
          aspect = "iso",
          xlab = "Prey",
          ylab = "Bait",
          main = "Ordered By Ascending CAI", 
          colorkey = FALSE, sub="")


##
@ 


\begin{figure}
  \centering

<<GavinImages, fig=TRUE, width=10, height=7, echo=FALSE>>=
par(mfcol = c(1,2))
plot(mat.random, split = c(1, 1, 2, 1), more = TRUE)
plot(mat.CAI, split = c(2, 1, 2, 1), more = FALSE)
@ 

       \caption{
         \label{fig:caiplots}{
           These plots present a view of the adjacency matrix for the VBP
           derived from the Gavin et al.~\cite{Gavin2006} experimental data set.
           An interaction between bait $b$ and prey $p$ is recorded by a dark 
           pixel in $(b,p)^{th}$ position of the matrix. The left panel has the
           rows and columns randomly ordered while the
           right panel has the rows and columns ordered by ascending
           values of each protein's condon adaptation index (CAI).
           Contrasting these two figures, we can ascertain that there is 
           a relationship between bait/prey interactions and CAI. 
           The relationship is based on proteins with 
           large un-reciprocated in-degree since the right panel shows a dark 
           vertical band. Had unreciprocated out-degree also been associated 
           with CAI then there would be a similar horizontal band reflected
           across the main diagonal of the matrix.
           }
       }
     \end{figure}

\subsection{Fisher's Exact Test Across Experiment}

Next we wanted to ascertain if the protein subset that was affected by 
a systematic bias in one experiment is related to the protein subset 
affected by a systematic bias of another experiment. To investigate this
relationship, we created three $2 \times 2$ tables. Only two datasets 
\cite{Gavin2006, Krogan2006} contained sufficient data points for this 
analysis. The $2 \times 2$ tables were created where the overall 
universe is VBP$_{C} = $ VBP$_{\mbs{G}} \mbox{ } \cap$ VBP$_{\mbs{K}}$.
\cite{Gavin2006} index the rows; \cite{Krogan2006}, the columns. 
In the $(2,2)$-entry of each table, we count the number of common 
proteins affected by a bias in both experiments; in $(1,2)$-entry,
we count the number affected in \cite{Gavin2006} only; in $(2,1)$, 
the number in \cite{Krogan2006} only; and in $(1,1)$, the number not 
affected in both. We can create three separate $2 \times 2$ tables:

\begin{itemize}
  \item Number of proteins identified by the two-sided binomial test.
  \item Number of proteins identified by the one-sided binomial test where
    in-degree is much larger than out-degree.
  \item Number of proteins identified by the one-sided binomial test where
    out-degree is much larger than in-degree.
\end{itemize}

<<twoBytwo, echo=FALSE, results=hide>>=

cache(vbpGraph <- mapply(function(x,y){subGraph(x, get(y))},vbp,bpExperimentNames))


cache(vbpStochastic <- lapply(vbpGraph, function(x) {if(length(nodes(x))!=0) 
                                                 idStochastic(x, bpGraph=TRUE)}))
cache(vbpSystematic <- mapply(function(x,y){setdiff(nodes(x),y)},
                        vbpGraph,vbpStochastic))

exp1 <- vbp[[11]]
exp2 <- vbp[[12]]
x <- intersect(exp1, exp2)
y <- matrix(0, nrow=length(x), ncol=2)
rownames(y) <- x
colnames(y) <- c("Gavin06","Krogan06")
y1 <- y
y2 <- y

cache(dG <- calcInOutDegStats(vbpGraph[[11]]))
cache(dK <- calcInOutDegStats(vbpGraph[[12]]))

gavLargeSysIn <- names(which((dG$inDegreeMinusOutDegree)[vbpSystematic[[11]]] > 0))
gavLargeSysOut <- names(which((dG$inDegreeMinusOutDegree)[vbpSystematic[[11]]] < 0))

kroLargeSysIn <- names(which((dK$inDegreeMinusOutDegree)[vbpSystematic[[12]]] > 0))
kroLargeSysOut <- names(which((dK$inDegreeMinusOutDegree)[vbpSystematic[[12]]] < 0))

indexG <- x %in% vbpSystematic[[11]]
indexK <- x %in% vbpSystematic[[12]]
indexG1 <- x %in% gavLargeSysIn
indexK1 <- x %in% kroLargeSysIn
indexG2 <- x %in% gavLargeSysOut
indexK2 <- x %in% kroLargeSysOut

y[indexG, 1] <- 1
y[indexK, 2] <- 1
z <- data.frame(y)

y1[indexG1, 1] <- 1
y1[indexK1, 2] <- 1
z1 <- data.frame(y1)

y2[indexG2, 1] <- 1
y2[indexK2, 2] <- 1
z2 <- data.frame(y2)

tab <- table(z$Gavin06, z$Krogan06)
tab2Way <- tab
ft <- fisher.test(tab)

tab1 <- table(z1$Gavin06, z1$Krogan06)
tab1WayIN <- tab1
ft1 <- fisher.test(tab1)

tab2 <- table(z2$Gavin06, z2$Krogan06)
tab1WayOUT <- tab2
ft2 <- fisher.test(tab2)

@ 

<<print2by2>>=
tab2Way
tab1WayIN
tab1WayOUT
@ 

We can use these three tables as the parameters for Fisher's Exact 
test (again a hypergeometric test), and see the results:

<<printFishers>>=
fisher.test(tab2Way)
fisher.test(tab1WayIN)
fisher.test(tab1WayOUT)
@ 

The Fisher tests show relatively small p-values and substantial
odds ratio for all three $2 \times 2$ tables though the most 
significant occurs for the one-sided binomial test when the 
in-degree dominates the out-degree. 


\subsection{Unreciprocated Degree Statistics}
Our Binomial model allows us to determine proteins that might be subject 
to a systematic bias of the experiment where each statistical test is 
conducted on a per protein level. In addition to these series of statistical 
test, we can describe experiment-wide bias by using the same binomial model 
for each protein. 

For each protein $\rho$ with directed degree $(i_{\rho},o_{\rho})$ and 
$n_{\rho} = i_{\rho}+o_{\rho}$, we can standardize the out-degree and 
compute the corresponding \emph{z-score} for each protein:

\begin{eqnarray}
z_{\rho} &=& \frac{\frac{1}{2}\;n_{\rho} - o_{\rho}}
{\sqrt{\left( \frac{1}{2} \right)^2\;n_{\rho}}}\\
    &=& \frac{i_{\rho}-o_{\rho}}{\sqrt{i_{\rho}+o_{\rho}}}
\end{eqnarray}

After calculating the z-score for each protein within an experiment, we 
were able to estimate the distributions within each dataset. Using the 
R \Rfunction{hist} and \Rfunction{density} functions, we were able to 
render the histograms for eleven of the datasets and the smooth density 
distribution for the three largest datasets.

<<zscore, echo=FALSE, results=hide>>=
normFunc <- function(ni, no) (ni-no)/(sqrt(ni+no))
if("Zhao2005BPGraph" %in% names(vbpGraph)){
  rm <- which(names(vbpGraph) == "Zhao2005BPGraph")
  vbpSG <- vbpGraph[-rm]
}
cache(deg <- lapply(vbpSG, calcInOutDegStats))
zScore <- lapply(deg, function(x) normFunc(x[["unrecipInDegree"]], x[["unrecipOutDegree"]]))
zScore1 <- lapply(zScore, function(x) x[!is.na(x)])
dNames <- sub("-$", "", sub("BPGraph", "-", bpExperimentNames))
dNames1 = dNames[-5]
m = round(sapply(zScore1, mean), digit=3)
dens <- lapply(zScore1, density)
sh <- lapply(zScore1, shorth)
@ 


<<zScoreHist, fig=TRUE, width=10, height=14, echo=FALSE, results=hide, include=FALSE>>=

par(mfrow = c(3,4), cex.main = 2, cex.lab=1.5, cex.axis=1.5)
mapply(function(x,y) {
  hist(x, main=y, col="#e6f598")},
  zScore1, dNames1)
@ 

\myincfig{fig-zScoreHist}{\textwidth}{Histograms of the out-degree z-scores.}

Histograms are plotted to determine the standard out-degree 
distributions (Figure~\ref{fig-zScoreHist}). We can see that for 
datasets such as 
\cite{Cagney2001, Tong2002, Hazbun2003}, there are relatively
few data points which yield little statistical power. Overall,
Only the \cite{Ito2001, Gavin2006, Krogan2006} plots showed
approximate unimodal distributions.

<<zScoreDens, fig=TRUE, width=9, height=9, prefix=TRUE, echo=FALSE, results=hide, include=FALSE>>=
par(mfrow = c(3,1))
for(i in c(1, 10, 11)) {
  z = zScore1[[i]]
  xlim = c(-1,1)*max(abs(quantile(z, probs=c(0.01, 0.99))))
  dens = density(z)
  plot.density(dens, main=paste("z-scores for ", dNames1[i], sep=""), 
    col="darblue", xlab="z", xlim=xlim, lwd=2)
  abline(v=c(0, median(z), shorth(z)), 
         col=c("#808080", brewer.pal(4, "Paired")[c(2,4)]), 
         lty=c(2,1,1), lwd=2)
}
@

\myincfig{fig-zScoreDens}{\textwidth}{Density plots for the three largest
bait/prey datasets.}
% FIXME: 
% 1. please explain what the various lines in this plot mean.
% 2. do we really need to show median and shorth? What is the point that we
%    are trying to make? Let's simplify and just present what actually need
%    to make the argument, not other tangential stuff.

For the three plots that appear to have unimodal distributions, we plotted 
their densities (Figure~\ref{fig-zScoreDens}). 
% FIXME: the plot for Ito does not look unimodal! Please, we should not talk
%  about submitting this paper this week and still have such howlers in there.

With more data points, we can 
better investigate these densities for possible biological associations. 
% FIXME: what does that mean


\newpage
%--------------------------------------------------
\section{Estimation of $\pfp$ and $\pfn$ by the method of moments}
%--------------------------------------------------
\subsection{Derivation}  
%--------------------------------------------------
\begin{tabular}{rp{0.25\textwidth}p{0.65\textwidth}}

$N \choose 2$&&The total number of possible interactions (excluding homomers)\\
$n$&&the true number of interactions\\
$n^c$&$={N \choose 2}-n$&the true number of non-interactions\\
$X_1$&&observed number of reciprocated edges\\
$X_2$&&observed number of non-edges\\
$X_3$&$=n+n^c-X_1-X_2$&observed number of unreciprocated eges
\end{tabular}
\par\vspace*{1ex}
\noindent we have
\begin{eqnarray}
E[X_1] &=& n\,(1-\pfn)^2+n^c\,\pfp^2\label{x1}\\
E[X_2] &=& n\,\pfn^2+n^c\,(1-\pfp)^2\label{x2}\\
E[X_3] &=& 2n\,\pfn(1-\pfn)+2n^c\,\pfp(1-\pfp)\label{x3}
\end{eqnarray}

Only two of the three equations~\eqref{x1}--\eqref{x3} are
independent, any two of them imply the third. 
Our goal is to estimate $\pfp$, $\pfn$. We can replace the
expectation values on the left side of
Equations~\eqref{x1}--\eqref{x3} by the observed sample values $x_1$,
$x_2$, $x_3$. Since we do not know $n$, the above system of two
independent equations for three variables defines a one-dimensional
solution manifold.

We will parameterize that manifold by $n$ ($0\le n\le {N \choose 2}$) in
$(\pfp,\pfn)$-space. Relevant solutions are those for which 
$0\le \pfp,\pfn \le 1$.

Consider that $n$ is given. Let us solve 
Equations~\eqref{x1}--\eqref{x3} for $\pfp$ and $\pfn$. First,
subtracting $\eqref{x4} = \eqref{x1} - \eqref{x2}$, we have
\begin{eqnarray}
x_1-x_2&=&n\,(1-2\pfn)-n^c\,(1-2\pfp)\label{x4}\\
\Leftrightarrow\quad
\pfn&=&\frac{1}{2n}\left((x_2-n^c)-(x_1-n)+2n^c\,\pfp\right)\nonumber\\
\pfn&=&\frac{1}{2n}\left(\Delta+2n^c\,\pfp\right),\label{q}
\end{eqnarray}
where we have defined $\Delta:= (x_2-n^c)-(x_1-n)$ for convenience.
We can plug this expression for $\pfn$ into Equation~\eqref{x2} and obtain
\begin{equation}
\underbrace{\left(n+n^c\right)}_{=:a} \pfp^2 + 
\underbrace{\left(\Delta-2n\right)}_{=:b} \pfp + 
\underbrace{n+\frac{\Delta^2}{4n^c}-\frac{n}{n^c}x_2}_{=:c} = 0.
\end{equation}
The equation $aw^2 + bw +c=0$ is solved by
\begin{equation}
w_{1,2}=\frac{-b\pm\sqrt{b^2-4ac}}{2a}.\label{p}
\end{equation}
Hence, the problem is solved: for data $N$, $x_1$, $x_2$
(from these, $x_3$ is implied) and for all possible (unknown) 
$n=0, 1, \ldots, {N \choose 2}$ 
we can calculate $\pfp$ via Equation~\eqref{p}, then $\pfn$ via
Equation~\eqref{q}. Only some of the theoretically possible 
values of $n$ will lead to admissible solutions for $\pfp$ and 
$\pfn$. This is exemplified in the following section.

%--------------------------------------------------
\subsection{Computation}  
%--------------------------------------------------
The function \Rfunction{estErrProbMethodOfMoments} in the
\Rpackage{ppiStats} package implements the computations described in
the previous section. 

%--------------------------------------------------
\subsubsection{Test on simulated data}  
%--------------------------------------------------
First, we want to gain confidence in the algorithm and its software
implementation by looking at simulated data.
The function \texttt{sim} calculates $E[X_1]$, $E[X_2]$ and $E[X_3]$ according
to Equations~\eqref{x1}--\eqref{x3}. Its arguments 
\texttt{pfp} ($\pfp$), \texttt{pfn} ($\pfn$),
\texttt{ntot} ($N$) need to be scalars, \texttt{n1} ($n$) can be a vector.
% 
<<simulate>>=
sim = function(n1, pfp, pfn, ntot) { 
##N   := ntot
##n   := n1
##n^c := n2
  nEdges = ntot*(ntot-1)/2
  stopifnot(length(pfp)==1, length(pfn)==1, length(ntot)==1, 
     all(n1<=nEdges)) 
  n2 = nEdges-n1
  cbind(x1 = n1*(1-pfn)^2 + n2*pfp^2,
        x2 = n1*pfn^2 + n2*(1-pfp)^2,
        x3 = 2*n1*pfn*(1-pfn)+2*n2*pfp*(1-pfp))
}
@ 
%
We consider the following example.
%

<<example>>=
ntot  = 2000
n1 = 12000
pfp = 0.001
pfn = 0.1
s = sim(n1=n1, pfp=pfp, pfn=pfn, ntot=ntot)
s
@ 
%
<<plotpfppfn, echo=FALSE, results=hide>>=
plotpfppfn = function(r, main, qmax=0.8, what="2", add=FALSE, ...) {

  p = r[, paste("pfp", what, sep="")]
  q = r[, paste("pfn", what, sep="")]
  cl = which((p>=0) & (p<=1) & (q>=0) & (q<=1))
  
  if(!add) {
    main = sprintf("%s -- sol. %s", main, what)
    if(any(cl, na.rm=TRUE)) {
      plot(p[cl], q[cl], type="l", xlab=expression(p[FP]), ylab=expression(p[FN]), 
           main=main, ylim=c(0, qmax), xlim=c(0, max(p[cl])), ...)
      sel = cl[round(seq(1, length(cl), length=4))]
      points(p[sel], q[sel], pch=16, col="orange")
      text(p[sel], q[sel], r[sel, "nint"], xpd=NA, col="blue")
    }
    else {
      plot(0:1, 0:1, main=main, xlab="p", ylab="q", type="n", ...)
      text(0.5, 0.5, "no solution")
    }
  } 
  else {
    lines(p[cl], q[cl], ...)
  } 
}
@ 
%
Now pretend we found data with 
$x_1=$\Sexpr{round(s[1, "x1"])},
$x_2=$\Sexpr{round(s[1, "x2"])} and
$x_3=$\Sexpr{round(s[1, "x3"])}, and we try out many possible values of 
\texttt{n1}. The plot is shown in Figure~\ref{fig-plotpqsim}.
%
<<plotpqsim, echo=TRUE,fig=TRUE,eps=FALSE,include=FALSE,width=5,height=5>>=
n1try = seq(1, 3*n1, by=12)
r = estErrProbMethodOfMoments(n1try, nrec=round(s[1,"x1"]), 
     nunr=round(s[1, "x3"]), ntot=ntot)
plotpfppfn(r, main=sprintf("Sim. data (ntot=%d, pfp=%g, pfn=%g)", ntot, pfp, pfn), qmax=0.35)
@
%
\myincfig{fig-plotpqsim}{0.7\textwidth}{The solution manifold.
  %The left column corresponds to ``+'' in Equation~\eqref{p},
  %the right column to ``-''.
  %The top row shows the whole range of solutions, the bottom row
  %only those with $0\le p,q \le 1$. 
The numbers in blue are the corresponding values of $n_1$, 
the corresponding (unknown) true number of interactions.}

We can also  verify that if we provide the correct value 
\texttt{n1}=\Sexpr{n1},
we recover the original probabilities:
%
<<solve2, print=TRUE>>=
res = estErrProbMethodOfMoments(n1, nrec=s[1, "x1"], nunr=s[1, "x3"], ntot=ntot)
@ 
%
<<echo=FALSE, results=hide>>=
tmpfun=function(x)
  if(!isTRUE(x))
    warning(sprintf("\n\nWarning\n%s\nPlease fixe me\n\n", x))
tmpfun(all.equal(res[1, "pfp2"], pfp))
tmpfun(all.equal(res[1, "pfn2"], pfn))
@ 
%--------------------------------------------------
\subsection{Application to the PPI datasets}
%--------------------------------------------------

<<getNrecNunr, echo=FALSE, results=hide>>=
getNrecNunr = function(x) {

##"/2" gets rid of the double counting via the 
##colSums call above and the addition operator below
   r =  colSums(getDegrees(x))/2
   c(nrow(x), r["nr"], r["ni"]+r["no"])
}
degs = eapply(bpMat, getNrecNunr)

@ 
%
<<degs, echo=FALSE, results=hide>>=
degs = sapply(degs, "(")
rownames(degs) = c("ntot", "nrec", "nunr")
degs

@ 

We now take the experimental datasets obtained from
\cite{Ito2001, Uetz2000, Cagney2001, Hazbun2003, Tong2002, 
Gavin2002, Ho2002, Krogan2004, Gavin2006, Krogan2006} to 
obtain the 1-dimensional manifolds.


<<pfppfnUnfiltSep, echo=FALSE, fig=TRUE, eps=FALSE,include=FALSE,width=8.5,height=12, results=hide>>=
par(mfrow=c(4,3))
for (i in 1:ncol(degs)) {
  n1 = seq(1, round(3*(sum(degs[c("nrec", "nunr"), i]))))
  r = estErrProbMethodOfMoments(n1, nrec=degs["nrec", i], 
     nunr=degs["nunr", i], ntot=degs["ntot", i])
  plotpfppfn(r, main = colnames(degs)[i])
}
@

We plot each dataset individually to ascertain the 
range for $\pfp$ and for $\pfn$. The result of this is plotted in 
Figure~\ref{fig-pfppfnUnfiltSep}. 

\newpage

\myincfig{fig-pfppfnUnfiltSep}{\textwidth}{The solution manifolds
  (one plot per dataset, unfiltered data).}


<<pfppfnAll2gether, echo=FALSE, fig=TRUE, eps=FALSE,include=FALSE,width=10,height=15, results=hide>>=
  colors = brewer.pal(6, "Set1")
  par(mfrow=c(2,2), pty="s", lwd=2)
  expts = list(APMS = grep("^Krogan|^Gavin|^Ho", colnames(degs), 
                 value=TRUE), Y2H = grep("^Ito|^Uetz|^Cagney|^Tong|^Hazbun", 
                                colnames(degs), value=TRUE))
  
  
  xmax = c(Y2H=0.055, APMS=0.02)
  
  nmaxFun = function(x) {floor(min(4*(sum(x[c("nrec", "nunr")])), 
    x["ntot"]*(x["ntot"]+1)/2))}
  
  counter <- 1
  
  for(what in names(expts)) {
    plot(c(0, xmax[what]), c(0,1), type="n", xlab=expression(p[FP]), 
         ylab=expression(p[FN]), 
         main=paste(what, "- Unfiltered Data", sep=" "), 
         sub=paste("(",letters[counter],")",sep=""),
         xlim=c(0,xmax[what]))

    newName <- sub("-$", "", sub("BPGraph", "-", expts[[what]]))
    legend(xmax[what], 1, newName, lty=1, lwd=2, 
           col=colors[seq(along=expts[[what]])], xjust=1, yjust=1)

    for (i in seq(along=expts[[what]])) {
      exnm = expts[[what]][i]    
      r = estErrProbMethodOfMoments(1:nmaxFun(degs[, exnm]), 
        nrec=degs["nrec", exnm], 
        nunr=degs["nunr", exnm], 
        ntot=degs["ntot", exnm])
      plotpfppfn(r, add=TRUE, col=colors[i])
    }
    counter = counter+1
    
  }
  
  degs1 = eapply(bpRed, getNrecNunr)
  degs1 <- sapply(degs1, "(")
  rownames(degs1) = c("ntot", "nrec", "nunr")
  
  for(what in names(expts)) {
    plot(c(0, xmax[what]), c(0,1), type="n", xlab=expression(p[FP]), 
         ylab=expression(p[FN]), 
         main=paste(what, "- Filtered Data", sep=" "), 
         sub=paste("(",letters[counter],")", sep=""), 
         xlim=c(0,xmax[what]))
    
    for (i in seq(along=expts[[what]])) {
      exnm = expts[[what]][i]    
      r = estErrProbMethodOfMoments(1:nmaxFun(degs1[, exnm]), 
        nrec=degs1["nrec", exnm], 
        nunr=degs1["nunr", exnm], 
        ntot=degs1["ntot", exnm])
      plotpfppfn(r, add=TRUE, col=colors[i])
    }
    counter <- counter+1
  }
  
@
%
Next we wanted to superimpose all experiments of the same type
(i.e. the same system was used to determine the interactions) 
so that we can compare the solutions curves across experiments.
We do this first on the set of VBP for each dataset, and
these are rendered in the top two plots. After, 
we filtered out the proteins likely to be affected by a 
systematic bias and recalibrated the solution curves. These 
are rendered in the bottom two plots.
The result of this is plotted in Figure~\ref{fig-pfppfnAll2gether}. 

\myincfig{fig-pfppfnAll2gether}{0.75\textwidth}{
  These figures detail the error statistics for each of the datasets.
  Plot $a$ generates the 1-dimensional solution curves for $(\pfp,\pfn)$
  parametrized by $n$ for the AP-MS datasets. Plot $b$ generates similar
  1-dimensional curves but for the Y2H datasets. Plots $c$ and $d$ 
  recalculates these solution curves for the AP-MS and Y2H respectively.
  These recalculations are done by setting aside those interactions 
  which appear to be affected by a systeamtic bias of the experimental 
  assay. Having set aside those interactions, the range for $\pfp$ is
  substantially constrained for the solution curves characterizing
  \cite{Gavin2006, Krogan2006} implying that systematic errors may 
  potentially have large effects on $\pfp$.}

\section{Cross Data Integration and Analysis}
We have shown that protein interaction analysis can be measured
by three quality metrics: 1. sampling, 2. proteins that might
be affected by systematic bias due to the experiment, and 3.
general stochastic variation. It is necessary to consider each of 
these three metrics if one would like to begin cross experimental
analysis. 

<<matrixPlot, fig=TRUE, width=10, height=10, prefix=FALSE, echo=FALSE, include=FALSE, results=hide>>=
firstx <- c(0, 0.6)
firsty <- c(0, 0.6)
secondx <- c(0.4, 0.9)
secondy <- c(0.4, 0.9)
colors <- c(brewer.pal(12, "Paired")[c(1,3,2)], "gray85")
lwd <- 2

grid.newpage()
pushViewport(viewport(width = 0.8, height = 0.8))
    
grid.lines(firstx, 1.05, gp = gpar(col = colors[1], lwd = lwd))
grid.text("Prey of Experiment 1", 0.15, 1.07,check.overlap=TRUE, 
          gp = gpar(col = colors[1], cex = 2))
grid.lines(-0.05, 1 - firsty, gp = gpar(col = colors[1], lwd = lwd),
           name = "Baits of Experiment 1")
grid.text("Baits of Experiment 1", -0.07, 0.855, gp = gpar(col = colors[1], 
                                              cex=2), rot=90)
grid.lines(secondx, 1.10, gp = gpar(col = colors[2], lwd = lwd),
           name = "Prey of Experiment 2")
grid.text("Prey of Experiment 2", 0.755, 1.085, gp = gpar(col = colors[2], 
                                              cex=2))
grid.lines(-0.10, 1 - secondy, gp = gpar(col = colors[2], lwd = lwd),
           name = "Baits of Experiment 2")
grid.text("Baits of Experiment 2", -0.083, 0.245, gp = gpar(col = colors[2], 
                                              cex=2), rot=90)
    
grid.rect(x = min(firstx, secondx),
          y = 1 - min(firstx, secondx),
          width = max(firstx, secondx) - min(firstx, secondx),
          height = max(firsty, secondy) - min(firsty, secondy),
          just = c("left", "top"),
          gp = gpar(fill = colors[4], col = "transparent"))

grid.rect(x = min(firstx),
          y = 1 - min(firstx),
          width = max(firstx) - min(firstx),
          height = max(firsty) - min(firsty),
          just = c("left", "top"),
          gp = gpar(fill = colors[1], col = "transparent"))


grid.rect(x = min(secondx),
          y = 1 - min(secondx),
          width = max(secondx) - min(secondx),
          height = max(secondy) - min(secondy),
          just = c("left", "top"),
          gp = gpar(fill = colors[2], col = "transparent"))

grid.rect(x = min(secondx),
          y = 1 - min(secondx),
          width = max(secondx) - min(secondx),
          height = max(secondy) - min(secondy),
          just = c("left", "top"),
          gp = gpar(fill = colors[2], col = "transparent"))

grid.rect(x = min(secondx),
          y = 1 - min(secondx),
          width = max(firstx) - min(secondx),
          height = max(firsty) - min(secondy),
          just = c("left", "top"),
          gp = gpar(fill = colors[3], col = "transparent"))

    
grid.rect()
@ 

\myincfig{matrixPlot}{\textwidth}{
  A schematic representation of the interactome coverage of two 
  protein interaction experiments. The adjacency matrix of the 
  complete interactome is represented by the large square. Experiment 
  1 covers a certain set of proteins as baits (rows covered by the
  light blue vertical line) and as prey (columns covered by the light 
  blue horizontal line). The tested interactions for Experiment 1 are 
  contained within the light blue rectangle. Similarly, 
  Experiment 2 covers another set of proteins and tests for a set of 
  interactions contained in the light green rectangle. The intersection 
  of the rectangles, the dark blue area, are the bait to prey interactions 
  tested by both experiments, and the union are the interactions tested 
  by at least one of the experiments. Note that the interactions in the 
  light gray area were tested by \emph{neither} experiment either because
  there are missing tested prey (upper right corner) or missing tested
  baits (lower left corner). The interactions in the white region are also
  tested by \emph{neither} experiment because both the baits and the prey
  were not tested.}

As an example we show how sampling is fundamental for 
inter-experimental analysis. 

The possible pitfalls of naive comparisons between two experimental
datasets are depicted in Figure~\ref{matrixPlot}. %~\ref{fig:matPlot}. 
The interactions in the intersection of the rectangles (darker blue) 
were tested by both; the interactions in the light blue and green 
areas were tested by one experiment but not the other; and the 
interactions in the light grey areas were tested by 
neither experiment. A data analysis that does not keep track of these
different sampling characteristics risks being misleading. Therefore,
sampling must be taken into consideration when integrating and 
comparing multiple datasets. Additionally, discrepancies will arise 
due to the set conditions of each experiment, and these discrepancies 
should be isolated from the variability across the experiments so 
the error rates have a more meaningful interpretation. Ultimately,
there are still many more steps needed to integrate datasets,
and we provide a few necessary components.

\begin{sidewaystable}[p]
\begin{center}
\begin{tabular}{rlrrrrrrrrrr}
  \hline
 & Ref. & VB & CB & TB & VB/TB & VP & VBP & VBP/BP & VP/VB & TI & TI/VB \\
  \hline
Ito2001 & \cite{Ito2001} & 1522 &  & 6604 & 0.23 & 2493 & 773 & 0.51 & 1.64 & 4524 & 2.97 \\
  Cagney2001 & \cite{Cagney2001} &  19 &  &  31 & 0.61 &  40 &  11 & 0.58 & 2.11 &  54 & 2.84 \\
  Tong2002 & \cite{Tong2002} &  20 &  &  22 & 0.91 &  59 &   5 & 0.25 & 2.95 & 115 & 5.75 \\
  Hazbun2003 & \cite{Hazbun2003} &  66 &  & 100 & 0.66 & 1940 &  28 & 0.42 & 29.39 & 2524 & 38.24 \\
  Zhao2005 & \cite{Zhao2005} &   1 &  &   1 & 1.00 &  90 &   0 & 0.00 & 90.00 &  90 & 90.00 \\
  Uetz2000-1 & \cite{Uetz2000} & 508 &  & 6604 & 0.08 & 630 & 142 & 0.28 & 1.24 & 952 & 1.87 \\
  Uetz2000-2 & \cite{Uetz2000} & 139 &  & 192 & 0.72 & 400 &  36 & 0.26 & 2.88 & 524 & 3.77 \\
  Gavin2002 & \cite{Gavin2002} & 455 & 600 & 725 & 0.63 & 1179 & 271 & 0.60 & 2.59 & 3419 & 7.51 \\
  Ho2002 & \cite{Ho2002} & 493 & 589 & 1739 & 0.28 & 1316 & 231 & 0.47 & 2.67 & 3687 & 7.48 \\
  Krogan2004 & \cite{Krogan2004} & 153 & 165 & 165 & 0.93 & 483 & 151 & 0.99 & 3.16 & 1132 & 7.40 \\
  Gavin2006 & \cite{Gavin2006} & 1752 & 1993 & 6466 & 0.27 & 1790 & 991 & 0.57 & 1.02 & 19105 & 10.90 \\
  Krogan2006 & \cite{Krogan2006} & 2264 & 2357 & 4562 & 0.50 & 5323 & 2226 & 0.98 & 2.35 & 63360 & 27.99 \\
   \hline
\end{tabular}
\caption{Overview of seven Y2H and five AP-MS experiments.
Abbreviations: VB - the number of viable baits; 
CB - the number of cloned (hybridized) baits, if available; 
TB - the total number of baits; 
VP - the number of viable prey; 
VBP - the number of proteins observed as both bait and prey;
TI - the total number of interactions observed.}
\label{table:perexpt}
\end{center}
\end{sidewaystable}

\begin{sidewaystable}[p]
\begin{center}

\begin{tabular}{rrrrrrrr}
  \hline
a) & Ito2001 & Cagney2001 & Tong2002 & Hazbun2003 & Zhao2005 & Uetz2000-1 & Uetz2000-2 \\
  \hline
Ito2001 &  &   9 &   7 &  24 &   1 & 224 &  47 \\
  Cagney2001 &  28 &  &   0 &   0 &   0 &   7 &   3 \\
  Tong2002 &  34 &   0 &  &   0 &   0 &   4 &   7 \\
  Hazbun2003 & 856 &  14 &  25 &  &   0 &  15 &  12 \\
  Zhao2005 &  43 &   1 &   2 &  38 &  &   0 &   0 \\
  Uetz2000-1 & 388 &  14 &  22 & 272 &  15 &  &  36 \\
  Uetz2000-2 & 200 &   9 &  26 & 204 &  13 & 108 &  \\
   \hline
\end{tabular}

\vspace*{4mm}

\begin{tabular}{rrrrrr}
  \hline
b) & Gavin2002 & Ho2002 & Krogan2004 & Gavin2006 & Krogan2006 \\
  \hline
Gavin2002 &  &  82 &  51 & 442 & 334 \\
  Ho2002 & 516 &  &  25 & 222 & 286 \\
  Krogan2004 & 299 & 246 &  & 121 & 151 \\
  Gavin2006 & 1143 & 717 & 371 &  & 1128 \\
  Krogan2006 & 1149 & 1277 & 478 & 1732 &  \\
   \hline
\end{tabular}
\caption{\label{table:betweenexpt}%
Pair-wise comparison of data sets. a) Y2H datasets, b) APMS datasets. 
Each table shows two distinct statistics: 
the values above the diagonal give the number of common viable baits 
between each pair of experiments, 
the values below the diagonal give the number of common viable prey.}
\end{center}
\end{sidewaystable}

@ 

\bibliographystyle{plain} 
\bibliography{proteinReview}
\end{document}
